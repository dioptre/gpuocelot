//
// Generated by LLVM NVPTX Back-End
//
// Tests ptr declarations in kernel function parameter attributes
//

.version 3.0
.target sm_10, texmode_independent
.address_size 64


	// .globl	matrixMul
.entry matrixMul(
	.param .u64 .ptr .global .align 4 matrixMul_param_0,
	.param .u64 .ptr .global .align 4 matrixMul_param_1,
	.param .u64 .ptr .global .align 4 matrixMul_param_2,
	.param .u64 .ptr .shared .align 4 matrixMul_param_3,
	.param .u64 .ptr .shared .align 4 matrixMul_param_4,
	.param .u32 matrixMul_param_5,
	.param .u32 matrixMul_param_6
)
{
	.reg .pred %p<396>;
	.reg .s16 %rc<396>;
	.reg .s16 %rs<396>;
	.reg .s32 %r<396>;
	.reg .s64 %rl<396>;
	.reg .f32 %f<396>;
	.reg .f64 %fl<396>;

	mov.u32	%r0, %ctaid.x;
	mov.u32	%r2, %ctaid.y;
	mov.u32	%r1, %tid.x;
	mov.u32	%r3, %tid.y;
	ld.param.u32 	%r7, [matrixMul_param_5];
	mul.lo.s32 	%r4, %r7, %r2;
	shl.b32 	%r5, %r4, 4;
	add.s32 	%r4, %r7, %r5;
	add.s32 	%r4, %r4, -1;
	setp.gt.s32 	%p0, %r5, %r4;
	ld.param.u64 	%rl0, [matrixMul_param_0];
	@%p0 bra 	BB0_1;
	ld.param.u32 	%r9, [matrixMul_param_6];
	ld.param.u64 	%rl8, [matrixMul_param_4];
	ld.param.u64 	%rl9, [matrixMul_param_3];
	ld.param.u64 	%rl1, [matrixMul_param_2];
	ld.param.u64 	%rl2, [matrixMul_param_1];
	mad.lo.s32 	%r5, %r3, %r7, %r1;
	shl.b32 	%r8, %r3, 4;
	add.s32 	%r6, %r8, %r1;
	mul.wide.s32 	%rl4, %r6, 4;
	add.s64 	%rl3, %rl9, %rl4;
	mad.lo.s32 	%r6, %r3, %r9, %r1;
	add.s64 	%rl4, %rl8, %rl4;
	shl.b32 	%r10, %r0, 4;
	cvt.s64.s32 	%rl5, %r10;
	shl.b32 	%r9, %r9, 4;
	cvt.s64.s32 	%rl6, %r9;
	mul.lo.s32 	%r7, %r2, %r7;
	shl.b32 	%r7, %r7, 4;
	cvt.s64.s32 	%rl7, %r7;
	mul.wide.s32 	%rl10, %r1, 4;
	add.s64 	%rl8, %rl8, %rl10;
	mul.wide.s32 	%rl10, %r8, 4;
	add.s64 	%rl9, %rl9, %rl10;
	mov.f32 	%f0, 0f00000000;
BB0_3:
	cvt.u32.u64 	%r7, %rl7;
	add.s32 	%r7, %r5, %r7;
	mul.wide.s32 	%rl10, %r7, 4;
	add.s64 	%rl10, %rl2, %rl10;
	cvt.u32.u64 	%r7, %rl5;
	add.s32 	%r7, %r6, %r7;
	mul.wide.s32 	%rl11, %r7, 4;
	add.s64 	%rl11, %rl1, %rl11;
	ld.global.f32 	%f1, [%rl10];
	st.shared.f32 	[%rl3], %f1;
	ld.global.f32 	%f1, [%rl11];
	st.shared.f32 	[%rl4], %f1;
	bar.sync	0;
	mov.u32 	%r7, 16;
	mov.u64 	%rl10, %rl9;
	mov.u64 	%rl11, %rl8;
BB0_4:
	ld.shared.f32 	%f1, [%rl11];
	ld.shared.f32 	%f2, [%rl10];
	mul.f32 	%f1, %f2, %f1;
	add.f32 	%f0, %f0, %f1;
	add.s64 	%rl11, %rl11, 64;
	add.s64 	%rl10, %rl10, 4;
	add.s32 	%r7, %r7, -1;
	setp.ne.s32 	%p0, %r7, 0;
	@%p0 bra 	BB0_4;
	bar.sync	0;
	add.s64 	%rl7, %rl7, 16;
	add.s64 	%rl5, %rl5, %rl6;
	cvt.u32.u64 	%r7, %rl7;
	setp.le.s32 	%p0, %r7, %r4;
	@%p0 bra 	BB0_3;
	bra.uni 	BB0_6;
BB0_1:
	mov.f32 	%f0, 0f00000000;
BB0_6:
	mov.u32	%r4, %ntid.y;
	mad.lo.s32 	%r2, %r4, %r2, %r3;
	cvt.s64.s32 	%rl1, %r2;
	mov.u32	%r2, %ntid.x;
	mov.u32	%r3, %nctaid.x;
	mul.lo.s32 	%r3, %r3, %r2;
	cvt.s64.s32 	%rl2, %r3;
	mad.lo.s32 	%r0, %r2, %r0, %r1;
	cvt.s64.s32 	%rl3, %r0;
	mad.lo.s64 	%rl1, %rl2, %rl1, %rl3;
	shl.b64 	%rl1, %rl1, 2;
	add.s64 	%rl0, %rl0, %rl1;
	st.global.f32 	[%rl0], %f0;
	ret;
}

